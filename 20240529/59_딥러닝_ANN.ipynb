{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f79ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8e63a",
   "metadata": {},
   "source": [
    "인공 신경 망(Artifical Neural Network, ANN)\n",
    "\n",
    "신경망의 개념\n",
    "\n",
    "다층 퍼셉트론(Multi Layer Perceptron)은 이름 그대로 퍼셉트론의 층이 여러개라는 뜻으로 다층 퍼셉트론은 기존의 데이터 공간을 변형함으로써 기존 하나의 퍼셉트론으로 해결할 수 없었던 문제를 해결할 수 있게 되는 것이다. 이처럼 다수의 뉴런을 사용해서 만든 것을 인공 신경망이라고 하며 줄여서 신경망이라 부른다.\n",
    "\n",
    "<img src=\"./ann01.png\" width=\"500\"/>\n",
    "\n",
    "입력층(input layer)에 입력된 데이터는 출력층(output layer)에 도달하기 전에 은닉층(hidden layer)이라는 층을 거친 후 출력층에 도달한다. 은닉층은 하나의 층뿐만 아니라 다수의 층으로 정할 수 있고 딥러닝이라는 이름은 이 은닉층의 깊이가 깊다는 뜻(함수가 깊게 중첩된다.)에서 나온 이름이다. 입력층의 노드 개수는 피쳐 개수와 동일하고 출력층의 노드 개수는 분류하려는 클래스 개수와 같다.\n",
    "\n",
    "출력층의 각 노드가 나타내는 숫자는 해당 클래스에 대한 점수이며 점수가 높을수록 해당 클래스에 속할 확률이 높다는 의미이고 최종적으로 점수가 가장 높은 클래스를 선정한다.\n",
    "\n",
    "신경망 함수는 $f(x) = f_3(f_2(f_1(x)))$와 같은 합성 함수 형태로 표현된다. $f_1$을 첫 번째 신경망 층, $f_2$를 두 번째 신경망 층, $f_3$을 세 번째 신경망 층 이라고 생각하면 된다. 신경망 층이 깊을수록 함수의 개수는 많아지고 합성 함수도 복잡해진다. 이때 합성 함수의 개수는 모델의 깊이(depth)를 의미하는데, 딥러닝에서 Deep이라는 용어가 바로 여기에서 나온 용어이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31dbfa",
   "metadata": {},
   "source": [
    "오차 역전파(Back Propagation)\n",
    "\n",
    "다층 퍼셉트론에서 최적값을 찾아가는 과정은 오차 역전파 방법을 사용한다.\n",
    "\n",
    "<img src=\"./ann02.png\" width=\"500\"/>\n",
    "\n",
    "입력층 → 은닉층 → 출력층 순서대로 흘러가는 것을 순전파(Forward Propagation)라고 하고 반대로 역전파는 출력층 → 은닉층 → 입력층 순서대로 반대로 거슬러 올라가는 방향이다. 오차 역전파를 기반으로 가중치와 편향값을 수정한 후 더 좋은 성능을 낼 수 있도록 모델을 개선한다.\n",
    "\n",
    "활성화 함수(Activation Function)\n",
    "\n",
    "활성화 함수는 딥러닝에서 입력값과 가중치 및 편향을 계산해서 해당 노드를 활성화 할지를 결정하는 함수이다. 딥러닝에서는 결과값을 결정하는 여러가지의 활성화 함수가 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc1aff",
   "metadata": {},
   "source": [
    "① 항등 함수(Identity Function)  \n",
    "항등 함수 또는 선형 함수(Linear Function)라고도 부르는 이 함수는 입력과 출력이 같은 값을 가진다. 주로 회귀 문제에서의 출력층 활성화 함수로 사용된다.  \n",
    "항등 함수는 아래의 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = x$$\n",
    "\n",
    "항등 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann09.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a3c96",
   "metadata": {},
   "source": [
    "② 계단 함수(Step Function)  \n",
    "계단 함수는 아래의 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \n",
    "\\begin{cases}\n",
    "0, \\; x \\leq 0 \\\\\n",
    "1, \\; x > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "계단 함수는 입력값이 0 이하일 경우 0을 출력하고, 0을 초과할 때만 1을 출력한다. 계단 함수의 출력은 0 또는 1로 오직 두 가지 값만 가진다는 특징이 있다.  \n",
    "계단 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann03.png\" width=\"400\"/>\n",
    "\n",
    "입력값 x가 0을 기준으로 0을 넘기 전과 후의 값에 따라 출력값이 바뀌는 것을 알 수 있다. 계단 함수는 사용하기 간단하다는 장점이 있지만 미분이 불가능하다는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8619a",
   "metadata": {},
   "source": [
    "③ 부호 함수(Sign Function)  \n",
    "부호 함수는 아래의 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \n",
    "\\begin{cases}\n",
    "1, \\; x > 0 \\\\\n",
    "0, \\; x = 0 \\\\\n",
    "-1, \\; x < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "부호 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann04.png\" width=\"400\"/>\n",
    "\n",
    "계단 함수와 비슷하게 생겼지만 0 또는 1만 출력하는 계단 함수와는 달리 -1, 0, 1 값을 출력하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50644ab1",
   "metadata": {},
   "source": [
    "④ 시그모이드 함수(Sigmoid Function)  \n",
    "시그모이드 함수는 아래와 같은 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "시그모이드 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann05.png\" width=\"400\"/>\n",
    "\n",
    "시그모이드 함수는 0과 1사이의 값을 출력한다.  \n",
    "시그모이드 함수를 딥러닝에 적용했을 때 단점은 학습하는 과정에서 미분을 반복하면 기울기 값이 매우 작아지는 기울 소실(Vanishing Gradient) 문제가 발생할 수 있다는 것이다. 시그모이드 함수에서 x값이 지나치게 크거나 작을 경우, 미분값이 0에 가까워지고 이는 기울기 소실 문제를 발생시켜 학습 속도가 느려질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07a92c",
   "metadata": {},
   "source": [
    "⑤ 렐루 함수(Rectified Linear Function, ReLu)  \n",
    "렐루 함수는 아래와 같은 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \n",
    "\\begin{cases}\n",
    "0, \\; x \\leq 0 \\\\\n",
    "x, \\; x > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "위 식은 아래와 같이 한 줄로도 표현할 수 있다.\n",
    "\n",
    "$$\\phi(x) = max(x, 0)$$\n",
    "\n",
    "렐루 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann07.png\" width=\"500\"/>\n",
    "\n",
    "렐루 함수는 x값이 0 이하라면 0을 출력하고, x값이 양수면 x값을 그대로 출력한다. 계단 함수, 부호 함수, 시그모이드 함수, 하이퍼볼릭 탄젠트 함수와는 다르게 출력값의 상한선이 없다는 특징이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd1de9",
   "metadata": {},
   "source": [
    "⑥ 리키 렐루 함수(Leaky ReLu Function)  \n",
    "렐루 함수는 아래와 같은 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \n",
    "\\begin{cases}\n",
    "ax, \\; x \\leq 0 \\\\\n",
    "x, \\; x > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "위 함수에서 $a \\leq 1$ 이라면 아래와 같이 쓸 수 있다.\n",
    "\n",
    "$$\\phi(x) = max(x, ax)$$\n",
    "\n",
    "리키 렐루 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann08.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f582af",
   "metadata": {},
   "source": [
    "⑦ 하이퍼볼릭 탄젠트 함수(Hyperbolic Tangent Function, tanh)  \n",
    "하이퍼볼릭 탄젠트 함수는 아래와 같은 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \\frac{exp(x) - exp(x)}{exp(x) + exp(x)}$$\n",
    "\n",
    "하이퍼볼릭 탄젠트 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann06.png\" width=\"500\"/>\n",
    "\n",
    "시그모이드 함수와 비슷하지만 시그모이드 함수의 출력 범위는 0부터 1 사이인 반면에 하이퍼볼릭 탄젠트 함수의 출력 범위 -1부터 1 사이이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1ad25",
   "metadata": {},
   "source": [
    "⑧ 소프트맥스 함수(Softmax Function)  \n",
    "소프트맥스 함수는 주로 최종 출력층에 사용되는 활성화 함수이다. 만약에 해결해야 할 문제가 회귀 문제라면 출력층에 항등 함수 함수를 사용하고 분류 문제일 경우에 소프트맥스 함수를 사용한다.  \n",
    "소프트맥스 함수는 아래와 같은 식을 따른다.\n",
    "\n",
    "$$\\phi(x) = \\frac{exp(x_k)}{\\sum_{i=1}^n exp(x_i)}$$\n",
    "\n",
    "소프트맥스 함수를 사용할 때 위 식을 그대로 사용할 경우 오버플로우 문제가 발생될 수 있다. 오버플로우는 출력값이 컴퓨터가 표현할 수 있는 수의 한계를 초과하는 문제를 말한다. 예를 들어 x<sub>k</sub> = 1000일 때, exp(1000)는 매우 큰 수가 되므로 계산하는 것이 불가능하다. 이 문제를 해결하기 위해 소프트맥스 함수를 아래와 같이 변형해서 쓰기도 한다.\n",
    "\n",
    "$$\\phi(x) = \\frac{exp(x_k + C)}{\\sum_{i=1}^n exp(x_i + C)}$$\n",
    "\n",
    "소프트맥스 함수에서 지수 연산을 할 때, 입력값에 임의의 상수 C를 더하거나 빼서 오버프로우 문제를 해결한다. 임의의 상수 C는 일반적으로 입력값의 최대값을 이용한다. 만약에 입력값이 999, 1000, 1001이라 하면 입력값의 최대값은 1001이므로 임의의 상수 C는 1001이 된다. exp(999), exp(1000), exp(1001)를 구해야 해서 오버플로우가 발생할 수 있지만, 입력값의 최대값을 빼주면 exp(-2), exp(-1), exp(0)와 같이 연산이 편해진다.\n",
    "\n",
    "소프트맥스 함수를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./ann10.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e8c42",
   "metadata": {},
   "source": [
    "배치 정규화(Batch Normalization)\n",
    "\n",
    "배치 정규화는 해당층의 값의 분포를 변경하는 방법으로, 평균과 분산을 고정시키는 방법이다. 배치 정규화를 이용하면 기울기 소실을 줄임으로써 신경망 학습 속도를 향상 시킬 수 있는 장점이 있다.\n",
    "\n",
    "드롭아웃(Dropout)\n",
    "\n",
    "신경망의 모든 노드를 사용하는 것이 아닌 일부 노드를 사용하는 방법이다.\n",
    "\n",
    "<img src=\"./ann11.png\" width=\"1000\"/>\n",
    "\n",
    "왼쪽 그림은 드롭아웃을 적용하기 전 신경망이고, 오른쪽 그림은 드롭아웃을 적용한 신경망이다.\n",
    "\n",
    "드롭아웃은 신경망에서 노드를 일시적으로 제거하는 방법이다. 어떤 노드를 신경망에서 제거할지는 각 계층에서 무작위로 선택된다. 드롭아웃을 적용하면 신경망의 노드 숫자가 줄어들고 이에 따라 연산량도 줄어들고 과대 적합을 방지할 수 있다는 장점이 있다.\n",
    "\n",
    "tensorflow 2.x 소개\n",
    "\n",
    "tensorflow는 파이썬을 이용해서 딥러닝 학습시 사용하는 라이브러리이다. tensorflow를 활용하면 신경망을 기본으로 하는 딥러닝에서 다양한 신경망 관련 연산을 처리할 수 있어 편리하다.\n",
    "\n",
    "tensorflow를 이용해 신경망 구조를 만드는 방법은 크게 시퀀스를 사용하는 방법과 함수를 사용하는 방법이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792703d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스를 사용하는 방법\n",
    "# Sequential 객체를 선언 후 Sequential 모델에 add() 메소드로 layer를 추가해서 쌓아올린다.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential() # layer를 순차적으로 쌓아올기 위한 Sequential 모델을 만든다.\n",
    "# 입력 layer는 input_shape 속성으로 입력 데이터 1건의 차원, units 속성으로 다음 layer로 전달되는 출력 차원,\n",
    "# activation 속성으로 활성화 함수를 지정해서 만든다.\n",
    "model.add(Dense(input_shape=(32, 32, 1), units=100, activation='relu')) # 입력 layer\n",
    "# 입력 layer를 입력 데이터의 차원을 지정하는 input_shape 속성이 필요하지만 입력 layer를 제외한 나머지\n",
    "# layer는 이전 layer의 출력이 현재 layer의 입력으로 들어오기 때문에 input_shape 속성이 필요없다.\n",
    "model.add(Dense(units=50, activation='relu')) # 히든 layer\n",
    "model.add(Dense(units=5, activation='softmax')) # 출력 layer\n",
    "# summary() 메소드로 만들어진 모델의 구조를 확인할 수 있다.\n",
    "model.summary()\n",
    "# Dense layer의 Param은 [(입력 개수 + 바이어스) * 출력 개수]으로 계산되고 바이어스는 layer당 1개 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28001303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 함수를 사용하는 방법\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "\n",
    "# 입력 layer\n",
    "input_layer = Input(shape=(32, 32, 1)) # 입력 데이터 1건의 차원을 지정한다.\n",
    "# layer = Dense(units=100)(input_layer) # 입력 layer를 만든다.\n",
    "# layer = Activation('relu')(layer) # 입력 layer에 활성화 함수를 지정한다.\n",
    "layer = Dense(units=100, activation='relu')(input_layer)\n",
    "# 히든 layer\n",
    "# layer = Dense(units=50)(layer) # 히든 layer를 만든다.\n",
    "# layer = Activation('relu')(layer) # 히든 layer에 활성화 함수를 지정한다.\n",
    "layer = Dense(units=50, activation='relu')(layer)\n",
    "# 출력 layer\n",
    "# output_layer = Dense(units=5)(layer) # 출력 layer를 만든다.\n",
    "# output_layer = Activation('softmax')(output_layer)\n",
    "output_layer = Dense(units=5, activation='softmax')(layer)\n",
    "# Model 객체에 입력 데이터 1건의 차원과 출력 레이어를 넘겨서 모델을 만든다.\n",
    "model = Model(input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a9ab",
   "metadata": {},
   "source": [
    "모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512d2c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장은 save() 메소드를 사용해서 'h5' 파일로 저장한다.\n",
    "# 'h5'는 'hdf5' 파일을 의미하고 'Hierarchical Data Format Version 5'의 줄인말로 대용량 데이터를\n",
    "# 저장하기 위한 파일 포맷이다.\n",
    "model.save('./data/ann_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e301acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32, 32, 100)       200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32, 32, 50)        5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32, 32, 5)         255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 'h5' 파일 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "ann_model = load_model('./data/ann_model.h5')\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7eed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
