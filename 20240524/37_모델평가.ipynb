{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ffece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.rcParams['font.size'] = 10\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aaa920",
   "metadata": {},
   "source": [
    "모델 평가\n",
    "\n",
    "오버피팅(overfitting)과 언더피팅(underfitting)  \n",
    "\n",
    "오버피팅은 특정 데이터 셋에 과도하게 적합된 것을 의미한다. 오버피팅이 발생하는 경우, 얼핏 정확도가 높아 보이지만 특정 데이터 셋에만 적합되어 알려지지 않은 데이터에 대한 예측력은 낮아지게 된다. 언더피팅은 데이터 셋에 적합이 잘되지 않은, 즉 과소적합된 것을 의미한다.  \n",
    "머신러닝을 통해 모델을 학습하는 이유는 데이터의 종류와 상관없이 일반화할 수 있는 모델을 생성하는 것이다. 주어진 데이터 셋에 대해 오버피팅이나 언더피팅이 발생한다면 새로운 데이터에 적용할 수 있는 좋은 모델이라고 말하기 어렵다.  \n",
    "오버피팅된 모델을 새로운 데이터셋에 적용한다면 학습 데이터 셋과는 큰 오차를 보인다. 반대로 언더피팅은 학습 데이터 셋과 테스트 데이터 셋 모두 큰 오차를 보인다.\n",
    "\n",
    "편향-분산 트레이드오프(bias-variance tradeoff)  \n",
    "\n",
    "편향 분산 트레이드오프란, 편향이 낮을수록 분산은 커지고, 반대로 편향이 높을수록 분산이 작아지는 경향이 있다는 것을 의미한다.  \n",
    "분산이 높은 현상은 주로 복잡한 모델에 나타나고 모델이 복잡하다는 말은 오버피팅이 발생할 가능성이 높다는 뜻이다. 즉, 복잡한 모델일수록 오버피팅이 발생할 가능성이 높으며, 이는 분산이 커진다는 것을 의미한다.  \n",
    "반대로 편향이 큰 현상은 주로 간단한 모델일 때 나타나는데 모델이 간단하다는 말은 언더피팅이 발생할 가능성이 높다는 뜻이다. 간단한 모델일수록 언더피팅이 발생할 가능성이 높으며, 이에 따라 편향이 커질 수 있다.\n",
    "\n",
    "크로스 벨리데이션(cross validation, 교차 검증)  \n",
    "\n",
    "모델을 생성한 후 실제 데이터에 적용해 보고 성능을 평가해야 하는데, 데이터 셋 전체를 학습에 사용하면 새롭게 적용할 데이터가 없어서 문제가 발생되기 때문에 전체 데이터를 학습 데이터와 테스트 데이터로 분할해서 사용한다. 학습 데이터는 학습하는 데 사용되고, 테스트 데이터는 학습 시에는 사용되지 않고 모델의 성능을 평가할 때 사용한다.  \n",
    "머신러닝 알고리즘을 적용할 때 다양한 하이퍼파라미터에 대해 여러 가지 모델 후보군을 생성하고 평가한 후 최종 모델을 선택하게 된다. 이때, 파라미터는 모델 내부에서 데이터에 의해 추정되는 값이고, 하이퍼파라미터는 사용자가 직접 정하는 값이다.  \n",
    "하이퍼파라미터를 결정하는 과정에서 학습 데이터와 테스트 데이터만 존재한다면 테스트 데이터에 의해 최종 모델의 파라미터가 결정된다. 즉, 모델의 하이퍼파라미터가 테스트 데이터에 의존한다는 뜻이다.  \n",
    "이 문제를 해결하기 위해 학습 데이터의 일부를 검증 데이터로 사용한다. 즉, 학습 데이터는 파라미터를 구하는데 사용하고, 검중 데이터는 하이퍼파라미터를 정하는데 사용한다.  \n",
    "주어진 데이터셋에 대해서 학습 데이터, 검증 데이터, 테스트 데이터로 분할할 수 있는 다양한 조합 방법이 존재한다. 이처럼 다양한 조합을 통해 모델의 성능을 검증하는 것을 크로스-밸리데이션이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a16a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets                         # 사이킷런이 제공하는 데이터 셋을 사용하기 위해 import 한다.\n",
    "from sklearn.model_selection import train_test_split # 학습 데이터와 테스트 데이터를 나누기 위해 import 한다.\n",
    "from sklearn.preprocessing import StandardScaler     # 표준화 스케일링을 하기 위해 import 한다.\n",
    "from sklearn.linear_model import LinearRegression    # 사이킷런이 제공하는 선형 회귀 모델을 사용하기 위해 import 한다.\n",
    "from sklearn.neighbors import KNeighborsClassifier   # 사이킷런이 제공하는 최근접 이웃 모델을 사용하기 위해 import 한다.\n",
    "from sklearn.pipeline import Pipeline                # 파이프라인을 사용하기 위해 import 한다.\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error      # 평균 절대값 오차(MAE)를 계산하기 위해 import 한다.\n",
    "from sklearn.metrics import mean_squared_error       # 평균 제곱 오차(MSE)를 계산하기 위해 import 한다.\n",
    "from sklearn.metrics import accuracy_score           # 정확도를 계산하기 위해 import 한다.\n",
    "from sklearn.metrics import confusion_matrix         # 혼동 행렬을 계산하기 위해 import 한다.\n",
    "from sklearn.metrics import classification_report    # 분류 리포트를 출력하기 위해 import 한다.\n",
    "from sklearn.metrics import r2_score                 # R 제곱값을 계산하기 위해 import 한다.\n",
    "from sklearn.metrics import silhouette_score         # 실루엣 스코어를 계산하기 위해 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba74040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런이 제공하는 보스턴 집값 데이터 셋에서 피쳐와 레이블 데이터 읽기\n",
    "raw_data = datasets.load_boston()\n",
    "xData = raw_data.data # 데이터\n",
    "yData = raw_data.target # 데이터에 따른 레이블\n",
    "print(xData.shape, yData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebbda2",
   "metadata": {},
   "source": [
    "파이프라인  \n",
    "\n",
    "머신러닝 과정에서 파이프라인을 사용하면 데이터 전처리와 학습 모델을 연결해 코드를 간결화 할 수 있다.\n",
    "\n",
    "파이프라인을 사용하지 않은 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e9abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13) (127, 13) (379,) (127,)\n",
      "29.51513779019758\n",
      "3.5678438946275453\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(xData, yData, random_state=7)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "# 표준화 스케일링 적용\n",
    "std_scale = StandardScaler()\n",
    "x_train = std_scale.fit_transform(x_train) # 학습 데이터 스케일링\n",
    "x_test = std_scale.transform(x_test) # 테스트 데이터 스케일링\n",
    "# 모델 생성 후 학습\n",
    "clf = LinearRegression() # 선형 회귀 모델을 만든다.\n",
    "clf.fit(x_train, y_train) # 스케일링된 학습 데이터와 학습 데이터에 따른 레이블로 학습시킨다.\n",
    "# 모델 예측\n",
    "predict = clf.predict(x_test) # 스케일링된 테스트 데이터로 학습된 모델을 예측한다.\n",
    "# 모델 평가\n",
    "# 테스트 데이터의 레이블과 테스트 데이터로 예측한 값의 평균 제곱 오차를 계산한다.\n",
    "print(mean_squared_error(y_test, predict))\n",
    "# 테스트 데이터의 레이블과 테스트 데이터로 예측한 값의 평균 절대값 오차를 계산한다.\n",
    "print(mean_absolute_error(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbcc10",
   "metadata": {},
   "source": [
    "파이프라인을 사용하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413ac96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.51513779019758\n",
      "3.5678438946275453\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(xData, yData, random_state=7)\n",
    "\n",
    "# 파이프라인 => 표준화 스케일링(전처리) + 학습 모델 객체 생성\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), # 표준화 스케일링 적용\n",
    "        ('linear_regression', LinearRegression()) # 선형 회귀 모델 적용\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 파이프라인에서 스케일러와 모델 생성 후 학습\n",
    "pipeline.fit(x_train, y_train)\n",
    "# 모델 예측\n",
    "predict = pipeline.predict(x_test)\n",
    "# 모델 평가\n",
    "print(mean_squared_error(y_test, predict))\n",
    "print(mean_absolute_error(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25b5db",
   "metadata": {},
   "source": [
    "그리드 서치(Grid Search)\n",
    "\n",
    "머신러닝 과정에서 관심있는 매개 변수들을 대상으로 학습 가능하도록 만드는 방식을 말한다.\n",
    "\n",
    "k-최근접 이웃 알고리즘 사용시 1부터 10 사이의 k값 후보 중 가장 높은 성능을 보이는 k값 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b370951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런이 제공하는 붓꽃 셋에서 피쳐와 레이블 데이터 읽기\n",
    "raw_data = datasets.load_iris()\n",
    "xData = raw_data.data\n",
    "yData = raw_data.target\n",
    "print(xData.shape, yData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c426abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4) (38, 4) (112,) (38,)\n",
      "k:  1, accuracy:  0.921\n",
      "k:  2, accuracy:  0.947\n",
      "k:  3, accuracy:  0.974\n",
      "k:  4, accuracy:  0.974\n",
      "k:  5, accuracy:  0.974\n",
      "k:  6, accuracy:  0.974\n",
      "k:  7, accuracy:  0.974\n",
      "k:  8, accuracy:  0.974\n",
      "k:  9, accuracy:  0.974\n",
      "k: 10, accuracy:  0.974\n",
      "best k:  3, accuracy:  0.974\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(xData, yData, random_state=0)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "# 표준화 스케일링 적용\n",
    "std_scale = StandardScaler()\n",
    "x_train = std_scale.fit_transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "best_accuracy = 0 # 최고 정확도를 기억할 변수를 선언하고 0으로 초기화 한다.\n",
    "# 1부터 10 사이의 k값 후보 중 가장 높은 성능을 보이는 k값을 찾는다.\n",
    "for k in range(1, 11):\n",
    "    # n_neighbors 인수로 k값을 넘겨서 최근접 이웃 모델을 만든다.\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 학습 데이터와 학습 데이터에 따른 레이블을 넘겨서 최근접 이웃 모델을 학습시킨다.\n",
    "    clf_knn.fit(x_train, y_train)\n",
    "    # 학습된 모델에 테스트 데이터를 넘겨서 예측한다.\n",
    "    predict = clf_knn.predict(x_test)\n",
    "    # 테스트 데이터의 레이블과 예측값을 넘겨서 정확도를 계산한다.\n",
    "    accuracy = accuracy_score(y_test, predict)\n",
    "    print('k: {:2d}, accuracy: {:6.3f}'.format(k, accuracy))\n",
    "    \n",
    "    # 가장 정확도가 높은 k를 계산한다.\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        final_k = k\n",
    "    # ===== if\n",
    "# ===== for\n",
    "print('best k: {:2d}, accuracy: {:6.3f}'.format(final_k, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b54c6",
   "metadata": {},
   "source": [
    "손실 함수(loss function)와 비용 함수(cost function)의 개념\n",
    "\n",
    "손실 함수는 머신러닝을 통해 생성한 모델이 실제값과 얼마나 차이가 나는지 즉, 손실 정도를 나타내는 함수로 모델 손실은 예측값과 실제값의 차이를 이용해 측정한다.  \n",
    "손실 함수와 비슷하게 비용 함수라는 개념도 존재하는데 손실 함수는 각 데이터 포인트에 대해서 예측값과 실제값의 차이를 나타내지만, 비용 함수는 데이터 셋 전체를 대상으로 하는 손실이다. 엄밀하게 말하면 서로 다르다고 한 수도 있으나 실제로는 손실 함수와 비용 함수를 구분없이 사용하기도 한다.\n",
    "\n",
    "손실 함수는 크게 L1 손실(L1 loss)과 L2 손실(L2 loss)이 존재한다.\n",
    "\n",
    "L1 손실 함수  \n",
    "L1 손실은 다른말로 L1 비용(L1 cost)이라고도 부르며, 아래와 같이 표현된다.\n",
    "\n",
    "$$L1 = \\sum |y_{true} - y_{predict}|$$\n",
    "\n",
    "$y_{true}$는 실제값을 의미하고 y_{predict}는 학습 모델을 이용해 예측한 값을 의미한다.  \n",
    "즉, L1 손실은 실제값과 예측값의 차이에 절대값을 취한것으로 실제값과 예측값의 차이를 줄이는 것이 목적이다.\n",
    "\n",
    "L1 손실과 관련된 비용 함수로 MAE(Mean Absolute Error)가 있다.\n",
    "\n",
    "$$MAE = \\frac {1}{n} \\sum_{i=1}^{n} |y_i - \\hat y|$$\n",
    "\n",
    "L2 손실 함수  \n",
    "L2 손실은 실제값과 예측값의 차이에 제곱을 취함으로써 구할 수 있다.\n",
    "\n",
    "$$L2 = \\sum (y_{true} - y_{predict})^2$$\n",
    "\n",
    "L2 손실을 이용한 비용 함수에는 MSE(Mean Squared Error), RMSE(Root Mean Squared Error)가 존재한다.\n",
    "\n",
    "$$MSE = \\frac {1}{n} \\sum_{i=1}^{n} (y_i - \\hat y)^2, \\; RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "MSE는 흔히 사용하는 비용 함수로 실제값과 예측값의 차이의 제곱의 평균을 의미하고 RMSE는 MSE에 제곱근을 취한 형태이다.  \n",
    "MSE를 구하는 과정에서 실제값과 예측값의 차이를 제곱하므로 MSE는 이상치(outlier)의 변화에 민감하다. 반면에 MAE나 RMSE는 이상치와 상관없이 안정된 값을 보여준다. 머신러닝에서 이상치에 중점을 두고 싶다면 MSE를 사용하고, 그렇치 않다면 MAE나 RMSE를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a4fd1",
   "metadata": {},
   "source": [
    "엔트로피(Entropy)\n",
    "\n",
    "엔트로피는 정보 이론에서 사용하는 개념으로 확률 변수의 불확실성 정도를 측정하기 위해 사용한다.\n",
    "\n",
    "$$Entropy(P) = - \\sum P(x)logP(x) = -E(logP(x))$$\n",
    "\n",
    "위 엔트로피 식은 Entropy(P)로 표시했지만 H(P) 혹은 H(X)라고 쓰기도 하며 엔트로피는 의사결정 트리에서 주로 사용한다.\n",
    "\n",
    "크로스 엔트로피\n",
    "\n",
    "$$Cross Entropy(P, Q) = - \\sum P(x)logQ(x) = -E_p(logQ(x))$$\n",
    "\n",
    "위 식은 크로스 엔트로피라고 하는데, 크로스 엔트로피는 하나의 분포를 대상으로 하는 반면, 크로스 엔트로피는 두 분포 P(x), Q(x)를 대상으로 엔트로피를 측정해서 두 분포간의 차를 계산한다. 머신러닝에서 크로스 엔트로피를 사용할 때는 P(x)를 실제 모형의 분포, Q(x)를 추정 모형의 분포라고 설정한다.\n",
    "\n",
    "쿨백-라이블러 발산\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{KL}(P||Q) =& \\sum P(x)log \\frac{P(x)}{Q(x)} \\\\\n",
    "=& -\\sum P(x)logQ(x) + \\sum P(x)logP(x) \\\\\n",
    "=& -E_p(log \\frac{P(x)}{Q(x)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "위 식은 쿨백-라이블러 발산(KLD)이라는 개념이다. 크로스 엔트로피와 쿨백-라이블러 발산은 머신러닝에서 자주 사용되는 손실 함수이다. 쿨백-라이블러는 다른 말로 상대적 엔트로피(Relative Entropy)라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d9fd2",
   "metadata": {},
   "source": [
    "모델 성능 평가에 필요한 개념\n",
    "\n",
    "True(정답)으로 분류되는 경우  \n",
    "데이터를 양성(Positive)으로 예측했을 때, 실제값도 양성일 경우 => TP(True Positive)  \n",
    "데이터를 음성(Negative)으로 예측했을 때, 실제값도 음성일 경우 => TN(True Negative)  \n",
    "\n",
    "False(오답)으로 분류되는 경우  \n",
    "데이터를 양성으로 예측했을 때, 실제값이 음성일 경우 => FP(False Positive)  \n",
    "데이터를 음성으로 예측했을 때, 실제값이 양성일 경우 => FN(False Negative)\n",
    "\n",
    "모델 성능 평가 지표\n",
    "\n",
    "정확도(Accuracy): 전체 데이터 중 양성으로 분류되는 비율 => $\\frac{TP+TN}{TP+TN+FP+FN}$  \n",
    "에러율(Error Rate): 전체 데이터 중 음성으로 분류되는 비율 => $\\frac{FP+FN}{TP+TN+FP+FN}$  \n",
    "\n",
    "정밀도(Precision): 양성으로 예측했을 때, 실제 양성으로 나타나는 비율 => $\\frac{TP}{TP+FP}$  \n",
    "특이도(Specificity): 음성으로 예측했을 때, 실제 음성으로 나타나는 비율 => $\\frac{TN}{TN+FN}$  \n",
    "\n",
    "재현율(Recall): 실제 양성에 해당되는 데이터가 양성으로 나타나는 비율 => $\\frac{TP}{TP+FN}$  \n",
    "FPR(False Positive Rate): 실제 음성에 해당되는 데이터가 양성으로 나타나는 비율 => $\\frac{FP}{TP+FN}$  \n",
    "\n",
    "f1 score: 정밀도와 재현율의 조화 평균값이다. 0부터 1 사이의 가지며 1에 가까울수록 높은 성능을 나타낸다. => $2 \\times \\frac{Precision \\times Recall}{Precision + Recall$\n",
    "\n",
    "머신러닝에서 풀어야 할 문제의 종류에 따라 모델 성능 평가 방법이 달라지기도 한다.\n",
    "\n",
    "분류 문제에서의 성능 평가\n",
    "\n",
    "정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed800542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "label = [0, 1, 2, 3] # 실제값\n",
    "predict = [0, 2, 2, 3] # 예측값\n",
    "# accuracy_score() 메소드로 실제값, 예측값을 인수로 넘겨서 정확도를 계산한다. 인수의 순서는 실제값, 예측값 순서로 지정한다.\n",
    "# accuracy_score() 메소드의 normalize 옵션의 기본값은 True이고 0부터 1 사이의 값으로 나타낸다.\n",
    "print(accuracy_score(label, predict))\n",
    "print(accuracy_score(label, predict, normalize=True))\n",
    "# normalize 옵션을 False로 지정하면 실제값과 예측값이 일치하는 빈도수를 출력한다.\n",
    "print(accuracy_score(label, predict, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ffbf8",
   "metadata": {},
   "source": [
    "혼동 행렬(Confusion Matrix)을 확인하면 실제값과 예측값의 빈도를 행렬 형태로 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041a8c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "[[2 0 0]\n",
      " [0 0 1]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "label = [2, 0, 2, 2, 0, 1] # 실제값\n",
    "predict = [0, 0, 2, 2, 0, 2] # 예측값\n",
    "print(accuracy_score(label, predict))\n",
    "# confusion_matrix() 메소드로 실제값, 예측값을 인수로 넘겨서 혼동 행렬를 출력한다. 인수의 순서는 실제값, 예측값 순서로 지정한다.\n",
    "print(confusion_matrix(label, predict))\n",
    "# 결과를 확인하면 위에서 부터 차례대로 클래스 0, 1, 2를 의미하고 행렬의 행은 실제값을 열은 예측값을 의미한다.\n",
    "# 즉, 주 대각 원소는 실제값과 예측값이 일치하는 경우를 의미하며, 주 대각 원소가 아닌 원소들은 실제값과 예측값이 차이가\n",
    "# 나는 경우를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0047cf",
   "metadata": {},
   "source": [
    "분류 리포트(Classidication Report)를 확인하면 여러가지 성능 점수를 한 눈에 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11115bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.44      0.56      0.49         6\n",
      "weighted avg       0.56      0.67      0.60         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = [2, 0, 2, 2, 0, 1] # 실제값\n",
    "predict = [0, 0, 2, 2, 0, 2] # 예측값\n",
    "# classification_report() 메소드로 실제값, 예측값을 인수로 넘겨서 분류 리포트를 출력한다. 인수의 순서는 실제값, 예측값 순서로 지정한다.\n",
    "print(classification_report(label, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb78da",
   "metadata": {},
   "source": [
    "회귀 문제에서의 성능 평가\n",
    "\n",
    "MAE(Mean Absolute Error): 실제값과 예측값의 차이의 절대값의 평균을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c18dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "label = [3, -0.5, 2, 7] # 실제값\n",
    "predict = [2.5, 0, 2, 8] # 예측값\n",
    "print(mean_absolute_error(label, predict))\n",
    "print(mean_absolute_error(predict, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132decd",
   "metadata": {},
   "source": [
    "MSE(Mean Squared Error): 실제값과 예측값의 차이의 제곱값의 평균을 의미한다.  \n",
    "RMSE(Root Mean Squared Error): 실제값과 예측값의 차이의 제곱값의 평균의 제곱근값을 의미한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d46b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.375\n",
      "0.6123724356957945\n",
      "0.6123724356957945\n"
     ]
    }
   ],
   "source": [
    "label = [3, -0.5, 2, 7] # 실제값\n",
    "predict = [2.5, 0, 2, 8] # 예측값\n",
    "print(mean_squared_error(label, predict))\n",
    "print(mean_squared_error(predict, label))\n",
    "print(np.sqrt(mean_squared_error(label, predict)))\n",
    "print(np.sqrt(mean_squared_error(predict, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace9495",
   "metadata": {},
   "source": [
    "R2 score는 R 제곱값이라고도 부르며 전체 모델에서 설명 가능한 분산의 비율을 나타낸다. 0에서 1 사이의 값을 가지며 1에 가까울수록 높은 성능을 의미한다.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^n(y_i - \\hat y)^2}{\\sum_{i=1}^n(y_i - \\bar y)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242374a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486081370449679\n"
     ]
    }
   ],
   "source": [
    "label = [3, -0.5, 2, 7] # 실제값\n",
    "predict = [2.5, 0, 2, 8] # 예측값\n",
    "# r2_score() 메소드로 실제값, 예측값을 인수로 받아 r2 score를 출력한다. 인수의 순서는 실제값, 예측값 순서로 지정한다.\n",
    "print(r2_score(label, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13874e18",
   "metadata": {},
   "source": [
    "군집 문제에서의 성능 평가\n",
    "\n",
    "군집 모델은 비지도 학습을 이용해 생성한 모델을 의미한다.\n",
    "\n",
    "실루엣 스코어(Silhouette Score)는 서로 다른 군집이 얼마나 잘 분리되어 있는지를 나타내는 지표이다. 같은 군집의 데이터는 가까운 거리에 뭉쳐있고, 다른 군집의 데이터는 멀리 떨어져 있을수록 높은 점수를 나타낸다.  \n",
    "실루엣 스코어는 아래와 같은 식으로 표현하고 -1부터 1사이의 값을 가지며 점수가 높을수록 좋은 성능을 의미한다.\n",
    "\n",
    "$$\\frac{b - a}{max(a, b)}$$\n",
    "\n",
    "위 식에서 a는 같은 클래스 내에서의 특정 데이터 포인트와 나머지 클래스 내의 다른 데이터 포인트 간의 평균 거리를 의미하고 b는 특정 데이터 포인트오 두 번째로 가까운 집단 내 데이터 포인트 간의 평균 거리를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4a9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5789497702625118\n"
     ]
    }
   ],
   "source": [
    "x_train = [[1, 2], [4, 5], [2, 1], [6, 7], [2, 3]] # 실제값\n",
    "label = [0, 1, 0, 1, 0] # 예측값\n",
    "# silhouette_score() 실제값, 예측값을 인수로 넘겨서 실루엣 스코어를 출력한다. 인수의 순서는 실제값, 예측값 순서로 지정한다.\n",
    "print(silhouette_score(x_train, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92403d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c368577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
