# cat API => 엘라스틱서치의 현재 상태를 빠르게 확인하는 기능을 제공한다.
# GET _cat을 요청하면 car API가 지원하는 목록을 확인한다.
GET _cat 

GET _cat/indices
GET _cat/indices?v

# 다음과 같은 데이터가 있다고 가정해보자.
# name: mike
# age: 25
# gender : male

# 관계형 데이터베이스는 데이터를 저장하려면 아래와 같이 테이블을 먼저 만들어야 한다.
# create table member (
#   id int not null auto_increment primary key,
#   name varchar(50) not null,
#   age int not null,
#   gender varchar(6) not null
# )

# 테이블이 작성되었으면 insert sql 명령을 실행한다.
# insert into member (name, age, gender) values ('mike', 25, 'male')

# mongodb도 그랬지만 elastic search도 json 형태로 저장한다.
# {
#   "name": "mike",
#   "age": 25,
#   "gender": "male"
# }

# 관계형 데이터베이스의 테이블은 mongodb는 컬렉션, elastic search는 인덱스라 부른다.
# 관계형 데이터베이스의 레코드는 mongodb나 elastic search 모두 도큐먼트라 부른다.

# 인덱스 만들기
# PUT 인덱스이름
PUT index
PUT index2

# 인덱스 전체 확인하기
GET index
GET index2

# 인덱스 삭제하기 => 인덱스가 삭제되면서 저장된 모든 도큐먼트도 같이 삭제된다.
DELETE index
DELETE index2

# ========================================================================================

# 인덱스를 만들면서 도큐먼트 입력하기
# 인덱스가 없으면 인덱스를 만들고 도큐먼트를 입력하고 인덱스가 있으면 기존 인덱스에
# 도큐먼트를 입력한다.
# 도큐먼트를 인덱스에 저장(포함)시키는 동작을 인덱싱이라고 한다.
# 도큐먼트는 json 형식으로 입력한다.
# PUT 인덱스이름/_doc/아이디
PUT index1/_doc/1
{
  "name": "mike",
  "age": 25,
  "gender": "male"
}
GET index1
# 인덱스의 매핑(데이터 구조)만 확인한다.
GET index1/_mapping

# 기존 인덱스에 도큐먼트 입력하기
# PUT 인덱스이름/_doc/아이디
PUT index1/_doc/2
{
  "name": "jane",
  "age": 20,
  "gender": "female"
}

# "country" 필드가 추가되고 "age", "gender" 필드는 사용하지 않지만 문제없이 인덱싱 된다.
PUT index1/_doc/3
{
  "name": "kim",
  "country": "korea"
}

# 데이터가 잘못된 도큐먼트 입력하기
# "age" 필드는 long 타입으로 매핑되었는데 text 타입으로 입력했다.
# 관계형 데이터베이스라면 오류가 발생했겠지만 유연하게 대응하는 엘라스틱서치는 데이터 타입을 변환해서 저장한다.
PUT index1/_doc/4
{
  "name": "hong",
  "age": "40",
  "gender": "male"
}

# ========================================================================================

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 조회하기
# GET 인덱스이름/_doc/아이디
# select * from index1 where _id = 1
GET index1/_doc/1
GET index1/_doc/2
GET index1/_doc/3
GET index1/_doc/4

# DSL(Domain Specific Language)을 이용해서 인덱스에 저장된 전체 도큐먼트 조회하기
# GET 인덱스이름/_search
# select * from index1
GET index1/_search

# ========================================================================================

# 도큐먼트 수정하기
# 존재하는 아이디에 실행하면 도큐먼트가 수정되고 존재하지 않는 아이디에 실행하면 도큐먼트가 입력된다.
# PUT 인덱스이름/_doc/아이디
PUT index1/_doc/1
{
  "name": "park",
  "age": 45,
  "gender": "female"
}

# PUT 명령으로 도큐먼트를 수정하면 기존에 저장된 모든 필드가 먼저 제거된 후 입력하는 내용으로 대체된다. => mongodb의 replaceOne() 처럼 실행된다.
PUT index1/_doc/2
{
  "name": "han"
}

# POST 명령을 사용해서 도큐먼트를 수정하면 저장되어있던 데이터는 그대로 유지되고 수정하는 데이터만 수정된다. => mongodb의 updateOne()이나 updateMany() 처럼 실행된다.
# POST 인덱스이름/_update/아이디
# update index1 set name = 'choi' where _id = 3
# {} 내부에 바로 수정할 내용을 입력하면 안되고 doc 블록을 만들고 doc 블록 내부에 수정할 내용을 입력해야 한다.
POST index1/_update/3
{
  "doc": {
    "name": "choi"
  } 
}

# ========================================================================================

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 삭제하기
# DELETE 인덱스이름/_doc/아이디
DELETE index1/_doc/1
DELETE index1/_doc/2
DELETE index1/_doc/3
DELETE index1/_doc/4
DELETE index1

# ========================================================================================

# 벌크(더미) 데이터
# 도큐먼트 CRUD 동작을 할 때 REST API를 호출해서 하나하나 도큐먼트를 요청하는 것 보다 벌크로 한번에 요청하는 것이 효율적이다.
# 벌크는 도큐먼트 읽기는 지원하지 않고 생성, 수정, 삭제만 지원한다.
# 벌크 데이터 형식은 삭제(delete)만 1줄로 작성하고 나머지(index, create, update) 작업들은 2줄로 작성한다. 각 줄 사이에는 쉼표 등의 구분자가 없고 사이의 빈 줄을 허용하지 않는다.

# 벌크로 데이터 입력하기
# POST _bulk
# { "index": { "_index": "인덱스이름", "_id": "아이디" } }
# { "필드이름": 저장할데이터, "필드이름": 저장할데이터, ... }
# "index"는 벌크 데이터로 입력되는 아이디가 인덱스에 존재하지 않으면 데이터를 입력하고 데이터로 입력되는 아이디가 인덱스에 존재하면 데이터를 수정한다.

POST _bulk
{ "index": { "_index": "index2", "_id": "1" } }
{ "name": "kang", "age": 30, "gender": "male" }
{ "index": { "_index": "index2", "_id": "2" } }
{ "name": "lee", "age": 50, "gender": "female" }

GET index2/_doc/1
GET index2/_doc/2
GET index2/_search
DELETE index2

# POST _bulk
# { "create": { "_index": "인덱스이름", "_id": "아이디" } }
# { "필드이름": 저장할데이터, "필드이름": 저장할데이터, ... }
# "create"는 벌크 데이터로 입력되는 아이디가 인덱스에 존재하지 않으면 데이터를 입력하고 데이터로 입력되는 아이디가 인덱스에 존재하면 에러가 발생된다.

POST _bulk
{ "create": { "_index": "index2", "_id": "3" } }
{ "name": "song", "age": 40, "gender": "male" }

GET index2/_doc/3

# 벌크로 데이터 수정하기
# POST _bulk
# { "update": { "_index": "인덱스이름", "_id": "아이디" } }
# { "doc": { "필드이름": 저장할데이터, "필드이름": 저장할데이터, ... } }
# 2번째 줄의 {} 내부에 바로 수정할 내용을 입력하면 안되고 doc 블록을 만들고 doc 블록 내부에 수정할 내용을 입력해야 한다.

POST _bulk
{ "update": { "_index": "index2", "_id": "1" } }
{ "doc": { "name": "jang", "age": 20, "gender": "female" } }
{ "update": { "_index": "index2", "_id": "2" } }
{ "doc": { "name": "ryu" } }

# 벌크로 데이터 삭제하기
# POST _bulk
# { "delete": { "_index": "인덱스이름", "_id": "아이디" } }
# 존재하지 않는 아이디의 도큐먼트를 제거하려 하면 에러는 발생되지 않는데 "status" : 404 메시지가 출력된다.

POST _bulk
{ "delete": { "_index": "index2", "_id": "3" } }

# ========================================================================================

# 벌크 데이터를 파일 형태로 만들어 적용하는 방법도 있다.
# 실제 현업에서는 파일로 만들어서 사용하는 방식이 더 실용적이다.
# 키바나 Dev tools에서는 파일 불러오기를 할 수 없기 때문에 커맨드 창에서 curl로 실행한다.

# 커맨드 창에서 아래와 같이 실행해서 벌크 데이터 파일을 만든다.
# C:\k_digital\kdigital\elasticStack>copy con bulk_index3
# { "index": { "_index": "index3", "_id": "1" } }
# { "name": "kang", "age": 30, "gender": "male" }
# { "index": { "_index": "index3", "_id": "2" } }
# { "name": "lee", "age": 50, "gender": "female" }
# ^Z
#         1개 파일이 복사되었습니다.

# 커맨드 창에서 아래와 같이 실행해서 벌크 데이터를 엘라스틱서치에 저장한다.
# -H는 curl의 헤더 옵션으로 ndjson 타입의 콘텐츠를 사용한다는 의미이다.
# -X는 요청 메소드를 기술하는데 POST 사용했다.
# localhost:9200은 엘라스틱 서치가 동작하는 호스트 주소이다.
# _bulk는 bulk API를 호출한다.
# --data-binary는 POST 메소드에 bulk_index3 파일을 바이너리 형태고 전송하라는 의미이다.
# C:\k_digital\kdigital\elasticStack>curl -H "Content-Type: application/x-ndjson" -XPOST 
# localhost:9200/_bulk --data-binary "@./bulk_index3"
# {"took":222,"errors":false,"items":[{"index":{"_index":"index3","_type":"_doc","_id":"1","_version":1,"result":"created","_shards":{"total":2,"successful":1,"failed":0},"_seq_no":0,"_primary_term":1,"status":201}},{"index":{"_index":"index3","_type":"_doc","_id":"2","_version":1,"result":"created","_shards":{"total":2,"successful":1,"failed":0},"_seq_no":1,"_primary_term":1,"status":201}}]}

GET index3/_search

# ========================================================================================

# 매핑
# 관계형 데이터베이스의 스키마(데이터 구조)와 같은 역할을 하는 것을 매핑이라고 한다.
# 엘라스틱서치가 검색 엔진으로 전문 검색과 대용량 데이터를 빠르게 실시간 검색할 수 있는 이유는 매핑이 있기 때문인데 매핑을 엘라스틱서치가 자동으로 하면 다이나믹(오토) 매핑이라 하고, 사용자가 직접 설정하면 명시적 매핑이라 한다.
# 엘라스틱서치는 문자열 타입을 text와 keyword 타입으로 나눌 수 있는데, 전문 검색을 활용하려면 이 두가지 타입을 이해하고 있어야 한다.

# 인덱스의 매핑 정보만 확인하기
# GET 인덱스이름/_mapping
GET index1/_mapping
GET index2/_mapping
GET index3/_mapping

# 다이나믹 매핑(dynamic mapping)
# 엘라스틱서치의 모든 인덱스는 매핑 정보를 가지고 있지만 유연한 활용을 위해 인덱스 생성 시 매핑 정의를 강제하지 않는다. index1, index2, index3 인덱스를 만들 때 따로 매핑을 설정하지 않았다. 하지만 도큐먼트가 인덱싱된 이유는 엘라스틱서치의 다이나믹 매핑 기능 때문이다.
# 다이나믹 매핑은 특별히 데이터 타입이나 스키마에 고민하지 않아도 json 도큐먼트의 데이터 타입에 맞춰 엘라스틱서치가 자동으로 인덱스를 매핑해주는 것이다.

# 원본 데이터 타입 => 다이나믹 매핑 데이터 타입
# null             => 필드를 추가하지 않는다.
# boolean          => boolean
# float            => float
# integer          => long
# object           => object
# string           => date, text/keyword

# ========================================================================================

# 명시적 매핑(explicit mapping)
# 인덱스 매핑을 사용자가 직접 정의하는 것을 말한다.

# 명시적 매핑 타입
# 텍스트
#   text: 전문 검색 => 텍스트 분석기가 텍스트를 작은 단위(단어)로 분리한다.
#     일반적으로 문장을 저장하는 매핑 타입으로 사용된다.
#     무조건적인 강제성은 없지만 일반적으로 문장 또는 여러 단어가 나열되는 문자열은
#     text 타입으로 지정한다.
#   keyword: 용어 검색, 정렬 또는 집계, 텍스트를 분리하지 않고 원문을 통째로 인덱싱 한다.
# 날짜
#   date: 날짜/시간 데이터
# 정수(고정 소수점)
#   byte: 8비트, -128 ~ 127
#   short: 16비트, -32768 ~ 32767
#   integer: 32비트, -2147483648 ~ 2147483647
#   long: 64비트, -2^63 ~ 2^63-1
# 실수(부동 소수점)
#   scaled float: 실수 데이터에 특정 값을 곱해서 정수형으로 바꾼 데이터
#   half_float: 16비트 실수
#   float: 32비트 실수, 단정도형
#   double: 64비트 실수, 배정도형
# 논리
#   boolean: true 또는 false만 값으로 가진다.
# IP 주소
#   ip: ipV4 또는 ipV6 타입의 ip 주소를 기억한다.
# 위치 정보
#   geo-point: 하나의 위치 포인트(위도, 경도)
#   geo-shape: 하나의 포인트가 아닌 임의의 지형
# 범위 설정
#   integer_range, long_range: 정수형 범위
#   float_range, double_range: 실수형 범위
#   ip_range: ip 주소 범위
#   date_range: 날짜 범위
# 객체
#   object: 계층 구조를 가지는 형태로 필드 안에 다른 필드들이 들어갈 수 있다.
# 배열
#   nested: 배열형 객체
#   join: 부모/자식 관계를 표현할 수 있다.

# ========================================================================================

# 인덱스 생성 시 명시적 매핑 설정 방법
# PUT 인덱스이름
# {
#   "mappings" : {
#     "properties" : {
#       "필드이름": {
#         "type": "필드타입"
#       },
#       ...
#     }
#   }
# }

PUT index4
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "age": {
        "type": "short"
      },
      "gender": {
        "type": "keyword"
      }
    }
  }
}
GET index4/_mapping

# ========================================================================================

# 멀티 필드를 활용한 문자열 처리
# 엘라스틱서치 5.x 버전부터 string 타입이 text와 keyword라는 두 가지 타입으로 분리되었다.

# text 타입
# 엘라스틱서치에서 text 타입은 일반적으로 문장을 저장하는 매핑 타입으로 사용된다.
# 강제성은 없지만 일반적으로 문장이나 여러 단어가 나열된 문자열은 text 타입으로 지정한다.
# text 타입으로 지정된 문자열은 분석기(analyzer)에 의해 토큰(token)으로 분리되고, 이렇게 분리된 토큰들은 인덱싱되는데 이를 역인덱싱(inverted indexing)이라 한다. 이때, 역인덱스에 저장된 토큰들을 용어(term)라고 한다.

POST _analyze
{
  "analyzer": "standard",
  "text": [
    "We offer solutions for enterprise search, observability, and security that are built on a single, flexible technology stack that can be deployed anywhere"
  ]
}

# ========================================================================================

# 텍스트가 [we, offer, solutions, ...]와 같이 토큰으로 분리되고, 불필요한 토큰은 걸러내고  대소문자를 통일하는 가공 과정을 거쳐 용어가 된다.
# 이런 용어들은 역인덱스에 저장되어 전문 검색을 할 수 있게 한다. 일반적으로 관계형 데이터베이스에 익숙할 경우 문자열 부분 검색으로 LIKE 검색을 떠올릴 텐데, LIKE 검색은 인덱싱이 되지 않아서 엘라스틱서치처럼 많은 문서를 처리하기엔 무리가 있다.

# text 타입을 가지는 인덱스 생성
PUT index5
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "text"
      }
    }
  }
}
GET index5/_mapping

# "beautiful today"는 타입이 text이기 때문에 분석기에 의해 [beautiful, today]와 같은 용어 단위로 분리되어 역인덱스에 저장된다.
PUT index5/_doc/1
{
  "contents": "beautiful today"
}
GET index5/_doc/1

# "beautiful day"는 타입이 text이기 때문에 분석기에 의해 [beautiful, day]와 같은 용어 단위로 분리되어 역인덱스에 저장된다.
PUT index5/_doc/2
{
  "contents": "beautiful day"
}
GET index5/_doc/2
GET index5/_search

# index5 인덱스 전문 쿼리
# "match"는 전문 검색을 실행하는 쿼리이며 "contents" 필드에 역인덱싱된 용어 중 일치하는 용어가 있는 도큐먼트를 찾는다.
GET index5/_search
{
  "query": {
    "match": {
      "contents": "today"
    }
  }
}

# text 타입의 경우 집계나 정렬을 지원하지 않으며, 매핑 파라미터로 집계나 정렬을 지원할 수는 있으나 메모리를 많이 사용하는 단점이 있다.
# text 타입으로 지정된 필드를 정렬할 경우 문장의 첫 문자열이 아닌 분해된 용어를 기준으로 정렬을 수행하므로 예상과는 다른 결과를 얻게된다.

# ========================================================================================

# 전문 검색이 아닌 집계나 정렬은 keyword 타입을 사용해야 한다.
# keyword 타입은 카테고리나 사람 이름, 브랜드 등 규칙성이 있거나 유의미한 값의 집합, 즉 범주형 데이터에 주로 사용된다. text 타입과 다르게 분석기를 거치지 않고 문자열 전체가 하나의 용어로 인덱싱된다.
# text 타입은 "beautiful today"라는 문자열을 [beautiful, today]으로 나눠서 역인덱스를 만들지만 keyword 타입은 [beautiful, today]라는 1개의 용어로 만든다.

# keyword 타입을 가지는 인덱스 생성
PUT index6
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "keyword"
      }
    }
  }
}
GET index6/_mapping

# "beautiful today"는 타입이 keyword이기 때문에 분석기를 사용하지 않고 [beautiful, today]를 1개의 용어로 저장한다.
PUT index6/_doc/1
{
  "contents": "beautiful today"
}
GET index6/_doc/1

# "beautiful day"는 타입이 keyword이기 때문에 분석기를 사용하지 않고 [beautiful, day]를 1개의 용어로 저장한다.
PUT index6/_doc/2
{
  "contents": "beautiful day"
}
GET index6/_doc/2
GET index6/_search

# index6 인덱스 전문 쿼리
GET index6/_search
{
  "query": {
    "match": {
      "contents": "beautiful"
    }
  }
}

# 위와 같이 실행하면 도큐먼트를 하나도 찾지 못한다.
# index5의 contents 필드는 text 타입이므로 전문 검색이 가능해서 "beautiful"를 검색하면 "beautiful"이 포함된 모든 도큐먼트가 검색되지만 index6의 contents 필드는 keyword 타입이므로 "beautiful"를 검색하면 "beautiful"로만 구성된 데이터가 없기 때문에 도큐먼트가 하나도 검색되지 않는다.

# ========================================================================================

# 멀티 필드
# 멀티 필드는 단일 필드의 입력에 대해 여러 하위 필드를 정의하는 기능으로 "fields"라는 매핑 파라미터가 사용된다.
# PUT 인덱스이름
# {
#   "mappings" : {
#     "properties" : {
#       "필드이름": {
#         "type": "필드타입",
#         "fields": {
#           "필드이름": {
#             "type": "필드타입"
#           }
#         }
#       },
#       ...
#     }
#   }
# }

# 멀티 필드를 가지는 생성
# "message" 필드는 text 타입만 사용한 단일 필드로 전문 검색만 가능하고 "contents" 필드는 text 타입과 keyword 타입을 사용한 멀티 필드로 전문 검색과 용어 검색이 모두 가능하다.
# "fields"라는 매핑 파라미터에 "keyword"라는 필드 이름을 사용했는데 반드시 "keyword"라는 이름을 사용할 필요는 없고 "abc"와 같은 이름을 사용해도 되지만 통상적으로 "keyword"라는 필드 이름을 많이 사용한다. => 다이나믹 매핑시에 "keyword"라는 이름으로 만들어진다.
PUT index7
{
  "mappings": {
    "properties": {
      "message": {
        "type": "text"
      },
      "contents": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
GET index7/_mapping
DELETE index7

PUT index7/_doc/1
{
  "message": "1 document",
  "contents": "beautiful day"
}
GET index7/_doc/1
GET index7/_search

PUT index7/_doc/2
{
  "message": "2 document",
  "contents": "beautiful today"
}
GET index7/_doc/2

PUT index7/_doc/3
{
  "message": "3 document",
  "contents": "wonderful day"
}
GET index7/_doc/3

PUT index7/_doc/4
{
  "message": "4 document",
  "contents": "beautiful today"
}
GET index7/_doc/4

# index7 인덱스의 "message" 필드 전문 쿼리
GET index7/_search
{
  "query": {
    "match": {
      "message": "document"
    }
  }
}

# index7 인덱스의 "contents" 필드 전문 쿼리
GET index7/_search
{
  "query": {
    "match": {
      "contents": "day"
    }
  }
}

# index7 인덱스의 "contents" 필드 용어 쿼리
# "match"는 전문 검색(부분 일치) 쿼리에 사용하고 "term"는 용어 검색(전체 일치) 쿼리에 사용한다.
# 용어 검색을 사용하기 위해 지정한 keyword 타입은 "contents" 필드의 하위 필드이므로 "contents" 필드 이름에 "."을 찍어서 "contents.keyword" 형태로 하위 필드에 접근해야 한다.
GET index7/_search
{
  "query": {
    "term": {
      "contents.keyword": "beautiful today"
    }
  }
}

# index7 인덱스의 "contents" 필드 집계 쿼리
# "aggs"는 집계를 하기 위한 쿼리이며 "contents.keyword" 필드의 값이 같은 도큐먼트가 그룹화된다.
# "aggs"와 같은 레벨의 "size"는 기본값이 20이고 집계를 계산하는데 사용된 데이터를 출력할 개수를 지정하고 "field"와 같은 레벨의 "size"는 기본값이 10이고 계산된 집계 결과를 출력할 개수를 지정한다.
GET index7/_search
{
  "size": 20, 
  "aggs": {
    "contents": {
      "terms": {
        "field": "contents.keyword",
        "size": 10
      }
    }
  }
}

# ========================================================================================

# 인덱스 템플릿
# 설정이 동일한 인덱스를 매번 일일이 작성하는 것은 비효율적일 뿐만 아니라 실수를 유발할 수 있다.
# 인덱스 템플릿은 설정이 동일한 복수의 인덱스를 만들 때 사용한다.

# 모든 인덱스 템플릿 확인하기
GET _index_template
# 특정 인덱스 템플릿 확인하기
# GET _index_template/인덱스템플릿이름
GET _index_template/ilm-history
# 인덱스 템플릿 이름에 와일드카드 문자(*)를 사용해서 인덱스 템플릿을 확인할 수 있다.
GET _index_template/.ml*

# 인덱스 템플릿이 적용되지 않은 인덱스
PUT test_index1
GET test_index1
DELETE test_index1

PUT test_index1/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index1/_doc/1
GET test_index1/_mapping

# 인덱스 템플릿 만들기
# 인덱스 템플릿을 만들 때 다양한 설정을 할 수 있지만, 일반적으로 mappings과 settings 설정을 많이 사용한다.

# "index_patterns" 파라미터는 새로 만들어지는 인덱스 중에서 인덱스 이름이 "index_patterns" 파라미터에서 지정한 패턴과 매칭되는 경우 인덱스 템플릿을 적용한다.
# 인덱스 템플릿을 만들기 전에 존재하던 인덱스들은 인덱스 템플릿의 영향을 받지 않는다.
# 즉, 인덱스 템플릿이 생성된 시점 이후에 작성되는 인덱스에 인덱스 템플릿이 적용된다.
# "priority" 파라미터는 인덱스 생성시 "index_patterns" 파라미터에서 지정한 패턴과 매칭되는 인덱스 템플릿이 2개 이상일 경우 인덱스 템플릿이 적용되는 우선 순위를 지정한다.
# 우선 순위는 숫자가 높은 템플릿이 먼저 적용된다.
# "template" 파라미터는 새로 생성되는 인덱스에 적용되는 "settings", "mappings"를 설정한다.
# PUT _index_template/인덱스템플릿이름
# {
#   "index_patterns": [],
#   "priority": ,
#   "template": {
#     "settings": {
#      
#     },
#     "mappings": {
#       "properties": {
#         "필드이름": {"type": 데이터타입}
#       }
#     }    
#   }
# }

PUT _index_template/test_template
{
  "index_patterns": ["test_*"],
  "priority": 1,
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "name": {
          "type": "text"
        },
        "age": {
          "type": "short"
        },
        "gender": {
          "type": "keyword"
        }
      }
    }
  }
}

# 인덱스 템플릿 삭제하기
# DELETE _index_template/인덱스템플릿이름
DELETE _index_template/test_template
GET _index_template/test_*

# 인덱스 템플릿이 적용된 인덱스 => test_template 템플릿의 명시작 매핑이 적용된다.
PUT test_index2
GET test_index2
DELETE test_index2

PUT test_index2/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index2/_doc/1
GET test_index2/_mapping

# 매칭되는 인덱스 템플릿이 없는 인덱스를 만든다. => 다이나믹 매핑이 적용된다.
PUT testindex1/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET testindex1/_doc/1
GET testindex1/_mapping

# 템플릿 매핑값과 다른 도큐먼트 인덱싱
# 템플릿에는 "age" 필드가 정수형으로 매핑이 되어 있는데, 인덱스에 저장할 도큐면트의 "age" 필드에는 정수로 형변환이 가능한 값("99")이 들어있으므로 정상적으로 처리된다.
PUT test_index2/_doc/2
{
  "name": "han",
  "age": "99"
}
GET test_index2/_doc/2

# 템플릿에는 "age" 필드가 정수형으로 매핑이 되어 있는데, 인덱스에 저장할 도큐면트의 "age" 필드에는 정수로 형변환이 불가능한 값("99 years")이 들어있으므로 "mapper_parsing_exception"가 발생된다.
PUT test_index2/_doc/3
{
  "name": "jang",
  "age": "99 years"
}
GET test_index2/_doc/2

# ========================================================================================

# "priority" 파라미터에 정의한 우선 순위 적용 확인하기 => 인덱스 템플릿이 2개 이상 필요하다.
# "multi_*" 패턴을 가지는 multi_template1 생성
PUT _index_template/multi_template1
{
  "index_patterns": ["multi_*"],
  "priority": 1,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "integer"},
        "name": {"type": "text"}
      }
    }
  }
}
DELETE _index_template/multi_template1

# "multi_data_*" 패턴을 가지는 multi_template2 생성
PUT _index_template/multi_template2
{
  "index_patterns": ["multi_data_*"],
  "priority": 2,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "short"},
        "name": {"type": "keyword"}
      }
    }
  }
}
DELETE _index_template/multi_template2

GET _index_template/multi_*

# multi_template1과 multi_template2의 "index_patterns"에 모두 매칭되는 인덱스를 만든다.
# multi_data_index 인덱스는 "index_patterns" "multi_*"에도 해당되고 "multi_data_*"에도 해당된다.
# "index_patterns"에 매칭되는 인덱스 템플릿이 여러개 이므로 "priority" 값이 가장 큰 인텍스 템플릿에 매칭된다.
PUT multi_data_index
GET multi_data_index/_mapping
DELETE multi_data_index

# multi_sample_index는 "index_patterns" "multi_*"에만 매칭되므로 multi_template1 인텍스 템플릿에 매칭된다.
PUT multi_sample_index
GET multi_sample_index/_mapping
DELETE multi_sample_index

# ========================================================================================

# 다이나믹 템플릿
# 다이나믹 템플릿은 매핑을 다이나믹하게 저장하는 템플릿 기술로 로그 시스템같은 비정형화된 데이터는 데이터의 구조를 알지 못하기 때문에 필드 타입을 정확히 정의하기 힘들고 필드의 개수를 정할 수 없는 경우도 있다.
# 다이나믹 템플릿은 매핑을 정확하게 할 수 없거나 대략적인 데이터 구조만 알고 있을 때 사용할 수 있는 방법이다.
# 인덱스를 만들 때 dynamic_templates []를 추가하면 된다.
# PUT dynamic_index1
# {
#   "mappings": {
#     "dynamic_templates": [
#       {
#         "다이나믹템플릿이름": {
#           "match_mapping_type": "자료형",
#           "mapping": {
#             "type": "자료형"
#           }
#         }
#       }
#     ]
#   }
# }

# "my_string_fields"는 임의로 정의한 다이나믹 템플릿 이름이다.
# 다이나믹 템플릿 이름 밑으로 2개의 설정이 있다.
# "match_mapping_type"는 조건문 혹은 매핑 트리거라 부르며 이 조건에 만족할 경우 데이터 타입이 결정된다. "match_mapping_type"에 "string"이 지정되어 있어서 문자열 타입의 데이터가 조건에 만족하는 데이터가 된다.
# "mapping"에서 조건에 만족하는 데이터를 매핑한다.
# 문자열 데이터는 keyword 타입으로 매핑되고 문자열이 아닌 데이터는 자기 자료형에 맞게 매핑된다.
PUT dynamic_index1
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_string_fields": {
          "match_mapping_type": "string",
          "mapping": {
            "type": "keyword"
          }
        }
      }
    ]
  }
}
GET dynamic_index1/_mapping

PUT dynamic_index1/_doc/1
{
  "name": "kim",
  "age": 20
}
GET dynamic_index1/_mapping

PUT dynamic_index1/_doc/2
{
  "name": "lee",
  "age": 30,
  "gender": true,
  "mean": 59.12
}
GET dynamic_index1/_mapping
