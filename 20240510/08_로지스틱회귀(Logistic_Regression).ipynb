{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c818a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\python37\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548b03d",
   "metadata": {},
   "source": [
    "로지스틱 회귀\n",
    "\n",
    "공부 시간, 과외 시간과 시험 점수 사이의 관계는 좌표로 나타냈을 때 형태가 직선으로 해결되는 선형 회귀를 사용하기에 적합했었다.  \n",
    "공부 시간, 과외 시간에 따른 시험 점수가 합격 여부로 발표되는 시험이 있을 경우 직선으로 해결하기에는 적합하지 못한 문제가 발생된다.  \n",
    "이럴때 사용하는 로지스틱 회귀는 참과 거짓 중에 하나를 내놓는 과정으로 참과 거짓을 구분한 'S'자를 눕혀놓은 형태의 선을 그어주는 작업이다.\n",
    "\n",
    "<img src=\"./sigmoid.png\" align=\"left\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19bf5b",
   "metadata": {},
   "source": [
    "http://taewan.kim/post/sigmoid_diff/  \n",
    "https://devlog.jwgo.kr/2018/04/16/sigmoid-graph-according-to-slope-change/#google_vignette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a46a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부 시간: [2, 4, 6, 8, 10, 12, 14], 합격 여부: [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]] # [공부 시간, 합격 여부]\n",
    "x = [i[0] for i in data] # 공부 시간\n",
    "y = [i[1] for i in data] # 합격 여부, 실제값\n",
    "print('공부 시간: {}, 합격 여부: {}'.format(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ab7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.65675126], b = [0.12050372]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.random_uniform([1], dtype=tf.float64)) # 공부 시간 기울기\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64)) # y절편\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('a = {}, b = {}'.format(sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb949bf",
   "metadata": {},
   "source": [
    "시그모이드 방정식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31962abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.e: 넘파이에서 지수값(2.718281828459045)을 의미하는 상수\n",
    "# print(np.e)\n",
    "Y = 1 / (1 + np.e ** -(a * x + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1cc43",
   "metadata": {},
   "source": [
    "시그모이드 방정식의 오차를 계산하는 수식을 만든다. => 시그모이드 함수의 특성은 예측값(Y)이 항상 0아니면 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fefa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -tf.reduce_mean(np.array(실제값) * tf.log(예측값) + (1 - np.array(실제값)) * tf.log(1 - 예측값))\n",
    "loss = -tf.reduce_mean(np.array(y) * tf.log(Y) + (1 - np.array(y)) * tf.log(1 - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743bc92",
   "metadata": {},
   "source": [
    "경사 하강법 알고리즘을 이용해서 오차를 최소로 하는 값을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb034e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab2b8b",
   "metadata": {},
   "source": [
    "학습 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a3d9d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:      0, loss:  0.8982, a:   0.2409, b:   0.9436\n",
      "epoch:   5000, loss:  0.0585, a:   1.5527, b: -10.6805\n",
      "epoch:  10000, loss:  0.0372, a:   2.0064, b: -13.8788\n",
      "epoch:  15000, loss:  0.0275, a:   2.3157, b: -16.0517\n",
      "epoch:  20000, loss:  0.0218, a:   2.5529, b: -17.7167\n",
      "epoch:  25000, loss:  0.0180, a:   2.7458, b: -19.0694\n",
      "epoch:  30000, loss:  0.0154, a:   2.9084, b: -20.2091\n",
      "epoch:  35000, loss:  0.0134, a:   3.0489, b: -21.1937\n",
      "epoch:  40000, loss:  0.0119, a:   3.1725, b: -22.0601\n",
      "epoch:  45000, loss:  0.0106, a:   3.2829, b: -22.8336\n",
      "epoch:  50000, loss:  0.0096, a:   3.3826, b: -23.5320\n",
      "epoch:  55000, loss:  0.0088, a:   3.4735, b: -24.1686\n",
      "epoch:  60000, loss:  0.0081, a:   3.5569, b: -24.7533\n",
      "epoch:  65000, loss:  0.0075, a:   3.6341, b: -25.2939\n",
      "epoch:  70000, loss:  0.0070, a:   3.7059, b: -25.7965\n",
      "epoch:  75000, loss:  0.0066, a:   3.7729, b: -26.2661\n",
      "epoch:  80000, loss:  0.0062, a:   3.8358, b: -26.7067\n",
      "epoch:  85000, loss:  0.0058, a:   3.8951, b: -27.1217\n",
      "epoch:  90000, loss:  0.0055, a:   3.9511, b: -27.5138\n",
      "epoch:  95000, loss:  0.0052, a:   4.0042, b: -27.8855\n",
      "epoch: 100000, loss:  0.0050, a:   4.0546, b: -28.2387\n",
      "epoch: 105000, loss:  0.0047, a:   4.1027, b: -28.5752\n",
      "epoch: 110000, loss:  0.0045, a:   4.1485, b: -28.8965\n",
      "epoch: 115000, loss:  0.0043, a:   4.1924, b: -29.2039\n",
      "epoch: 120000, loss:  0.0042, a:   4.2345, b: -29.4985\n",
      "epoch: 125000, loss:  0.0040, a:   4.2749, b: -29.7814\n",
      "epoch: 130000, loss:  0.0038, a:   4.3138, b: -30.0534\n",
      "epoch: 135000, loss:  0.0037, a:   4.3512, b: -30.3154\n",
      "epoch: 140000, loss:  0.0036, a:   4.3872, b: -30.5680\n",
      "epoch: 145000, loss:  0.0034, a:   4.4221, b: -30.8119\n",
      "epoch: 150000, loss:  0.0033, a:   4.4558, b: -31.0477\n",
      "epoch: 155000, loss:  0.0032, a:   4.4884, b: -31.2759\n",
      "epoch: 160000, loss:  0.0031, a:   4.5199, b: -31.4970\n",
      "epoch: 165000, loss:  0.0030, a:   4.5505, b: -31.7114\n",
      "epoch: 170000, loss:  0.0029, a:   4.5803, b: -31.9194\n",
      "epoch: 175000, loss:  0.0029, a:   4.6091, b: -32.1215\n",
      "epoch: 180000, loss:  0.0028, a:   4.6372, b: -32.3180\n",
      "epoch: 185000, loss:  0.0027, a:   4.6645, b: -32.5092\n",
      "epoch: 190000, loss:  0.0026, a:   4.6911, b: -32.6953\n",
      "epoch: 195000, loss:  0.0026, a:   4.7170, b: -32.8767\n",
      "epoch: 200000, loss:  0.0025, a:   4.7422, b: -33.0535\n",
      "epoch: 205000, loss:  0.0024, a:   4.7669, b: -33.2260\n",
      "epoch: 210000, loss:  0.0024, a:   4.7909, b: -33.3944\n",
      "epoch: 215000, loss:  0.0023, a:   4.8144, b: -33.5589\n",
      "epoch: 220000, loss:  0.0023, a:   4.8374, b: -33.7196\n",
      "epoch: 225000, loss:  0.0022, a:   4.8598, b: -33.8767\n",
      "epoch: 230000, loss:  0.0022, a:   4.8818, b: -34.0304\n",
      "epoch: 235000, loss:  0.0021, a:   4.9033, b: -34.1808\n",
      "epoch: 240000, loss:  0.0021, a:   4.9243, b: -34.3281\n",
      "epoch: 245000, loss:  0.0020, a:   4.9449, b: -34.4724\n",
      "epoch: 250000, loss:  0.0020, a:   4.9651, b: -34.6138\n",
      "epoch: 255000, loss:  0.0020, a:   4.9849, b: -34.7524\n",
      "epoch: 260000, loss:  0.0019, a:   5.0043, b: -34.8883\n",
      "epoch: 265000, loss:  0.0019, a:   5.0234, b: -35.0216\n",
      "epoch: 270000, loss:  0.0019, a:   5.0421, b: -35.1525\n",
      "epoch: 275000, loss:  0.0018, a:   5.0604, b: -35.2810\n",
      "epoch: 280000, loss:  0.0018, a:   5.0784, b: -35.4072\n",
      "epoch: 285000, loss:  0.0018, a:   5.0961, b: -35.5311\n",
      "epoch: 290000, loss:  0.0017, a:   5.1135, b: -35.6530\n",
      "epoch: 295000, loss:  0.0017, a:   5.1306, b: -35.7727\n",
      "epoch: 300000, loss:  0.0017, a:   5.1475, b: -35.8905\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(300001):\n",
    "    sess.run(gradient_descent)\n",
    "    if epoch % 5000 == 0:\n",
    "        print('epoch: %6d, loss: %7.4f, a: %8.4f, b: %8.4f' % (epoch, sess.run(loss), sess.run(a), sess.run(b)))\n",
    "        '''\n",
    "        print('epoch: {:6d}, loss: {:7.4f}, a: {:8.4f}, b: {:8.4f}'.format(\n",
    "            epoch, sess.run(loss), sess.run(a)[0], sess.run(b)[0]\n",
    "        ))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cf75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3708a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
